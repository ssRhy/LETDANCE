#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LETDANCE å›¾åƒåˆ†æå·¥å…·
åŸºäºLangChainçš„å›¾åƒåˆ†æå·¥å…·ï¼Œæ”¯æŒæ‘„åƒå¤´æ‹ç…§å’ŒAzure OpenAIå›¾åƒåˆ†æ
"""

import os
import cv2
import json
import time
import base64
import logging
import numpy as np
from datetime import datetime
from typing import Optional, Dict, List, Type, Any

from langchain_core.tools import BaseTool
from langchain_core.callbacks import CallbackManagerForToolRun
from pydantic import BaseModel, Field

try:
    from openai import AzureOpenAI
    AZURE_AVAILABLE = True
except ImportError:
    AZURE_AVAILABLE = False
    logging.warning("Azure OpenAIæœªå®‰è£…ï¼Œå›¾åƒåˆ†æåŠŸèƒ½å°†ä¸å¯ç”¨")

# å¯¼å…¥å›¾åƒå­˜å‚¨ç®¡ç†å™¨
from .image_storage_utils import storage_manager

# Azure OpenAIé…ç½®å·²ç›´æ¥å¡«å…¥ï¼Œæ— éœ€å¯¼å…¥config

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

def ensure_json_serializable(obj):
    """ç¡®ä¿å¯¹è±¡å¯ä»¥JSONåºåˆ—åŒ–"""
    if isinstance(obj, dict):
        return {k: ensure_json_serializable(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [ensure_json_serializable(item) for item in obj]
    elif isinstance(obj, (np.integer, np.floating, np.ndarray)):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        else:
            return obj.item()
    elif isinstance(obj, (int, float, str, bool, type(None))):
        return obj
    else:
        return str(obj)

class ImageAnalysisInput(BaseModel):
    """å›¾åƒåˆ†æå·¥å…·è¾“å…¥æ¨¡å‹"""
    action: str = Field(
        description="æ“ä½œç±»å‹ï¼š'capture_and_analyze'(æ‹ç…§å¹¶åˆ†æ), 'analyze_file'(åˆ†ææ–‡ä»¶), 'get_summary'(è·å–æ±‡æ€»)"
    )
    image_path: Optional[str] = Field(
        default=None,
        description="å›¾åƒæ–‡ä»¶è·¯å¾„ï¼ˆå½“actionä¸ºanalyze_fileæ—¶å¿…éœ€ï¼‰"
    )
    analysis_prompt: Optional[str] = Field(
        default="è¯·åˆ†æè¿™å¼ å›¾ç‰‡ä¸­çš„äººç‰©æƒ…æ„ŸçŠ¶æ€ï¼Œå¹¶æ ¹æ®æƒ…æ„Ÿæ¨èåˆé€‚çš„éŸ³ä¹é£æ ¼ã€‚åŒ…æ‹¬ï¼š1.äººç‰©è¡¨æƒ…å’Œè‚¢ä½“è¯­è¨€åˆ†æ 2.æƒ…æ„ŸçŠ¶æ€åˆ¤æ–­ 3.éŸ³ä¹é£æ ¼æ¨è",
        description="è‡ªå®šä¹‰åˆ†ææç¤ºè¯"
    )

class ImageAnalysisTool(BaseTool):
    """LangChainå›¾åƒåˆ†æå·¥å…·"""
    
    name: str = "image_analysis"
    description: str = """
    å›¾åƒåˆ†æå·¥å…·ï¼Œæ”¯æŒä»¥ä¸‹åŠŸèƒ½ï¼š
    1. æ‹ç…§å¹¶åˆ†æï¼šä»æ‘„åƒå¤´æ‹ç…§å¹¶è¿›è¡ŒAIåˆ†æ
    2. åˆ†ææ–‡ä»¶ï¼šåˆ†ææŒ‡å®šçš„å›¾åƒæ–‡ä»¶
    3. è·å–æ±‡æ€»ï¼šè·å–åˆ†æç»“æœæ±‡æ€»
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
    - {"action": "capture_and_analyze"} - æ‹ç…§å¹¶åˆ†ææƒ…æ„Ÿ
    - {"action": "analyze_file", "image_path": "photo.jpg"} - åˆ†ææŒ‡å®šæ–‡ä»¶
    - {"action": "get_summary"} - è·å–åˆ†ææ±‡æ€»
    """
    args_schema: Type[BaseModel] = ImageAnalysisInput
    # ç§»é™¤ return_directï¼Œè®©Agentèƒ½å¤Ÿå¤„ç†å·¥å…·è¾“å‡º
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        # å»¶è¿Ÿåˆå§‹åŒ–ç»„ä»¶ï¼Œé¿å…åœ¨å·¥å…·åˆ›å»ºæ—¶å°±åŠ è½½æ‰€æœ‰ä¾èµ–
        self._azure_client = None
        self._camera_manager = None
        self._analysis_results = []
    
    def _get_camera_manager(self):
        """è·å–æ‘„åƒå¤´ç®¡ç†å™¨ï¼ˆç®€åŒ–ç‰ˆï¼Œç›´æ¥ä½¿ç”¨OpenCVï¼‰"""
        # ä¸å†ä¾èµ–å¤–éƒ¨camera_manageræ¨¡å—ï¼Œç›´æ¥è¿”å›Trueè¡¨ç¤ºå¯ç”¨
        logger.info("ä½¿ç”¨å†…ç½®æ‘„åƒå¤´ç®¡ç†")
        return True
    
    def _get_azure_client(self):
        """è·å–Azure OpenAIå®¢æˆ·ç«¯ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰"""
        if self._azure_client is None:
            if not AZURE_AVAILABLE:
                logger.error("Azure OpenAIæœªå®‰è£…")
                self._azure_client = False
                return None
            
            try:
                # é…ç½®ä»£ç†è®¾ç½®
                try:
                    from proxy_manager import configure_proxy_settings
                    configure_proxy_settings()
                except ImportError:
                    logger.warning("ä»£ç†ç®¡ç†å™¨æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤ç½‘ç»œè®¾ç½®")
                
                self._azure_client = AzureOpenAI(
                    azure_endpoint="https://ai-philxia4932ai122623990161.openai.azure.com/",
                    api_key="ES3vLOAy8MUTMui8udIAk2vZO1Fo7qCBHKlaAvcprOXicYTkjzwbJQQJ99BDACHYHv6XJ3w3AAAAACOG4FT8",
                    api_version="2024-02-15-preview"
                )
                logger.info("Azure OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.error(f"Azure OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
                self._azure_client = False
        
        return self._azure_client if self._azure_client is not False else None
    
    def _capture_photo(self) -> Optional[Dict[str, Any]]:
        """ä»æ‘„åƒå¤´æ‹ç…§å¹¶è¿”å›å›¾åƒæ•°æ®å’Œä¿å­˜è·¯å¾„ï¼ˆæ”¹è¿›ç‰ˆï¼Œä½¿ç”¨ç»Ÿä¸€çš„æ‘„åƒå¤´æ¥å£ï¼‰"""
        import gc
        
        # å¼ºåˆ¶æ¸…ç†èµ„æº
        gc.collect()
        
        cap = None
        try:
            # å°è¯•ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ‘„åƒå¤´
            for camera_id in range(3):
                try:
                    print(f"å°è¯•æ‰“å¼€æ‘„åƒå¤´ {camera_id} è¿›è¡Œæ‹ç…§...")
                    cap = cv2.VideoCapture(camera_id)
                    if cap.isOpened():
                        # è®¾ç½®æ‘„åƒå¤´å‚æ•°
                        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                        
                        # ç­‰å¾…æ‘„åƒå¤´ç¨³å®š
                        time.sleep(1)
                        
                        # å°è¯•è¯»å–å‡ å¸§ï¼Œå–æœ€åä¸€å¸§
                        for _ in range(3):
                            ret, frame = cap.read()
                            if ret and frame is not None:
                                break
                        
                        if ret and frame is not None and frame.size > 0:
                            print(f"âœ… æˆåŠŸä»æ‘„åƒå¤´ {camera_id} æ‹ç…§")
                            
                            # å°†å›¾åƒç¼–ç ä¸ºå­—èŠ‚æ•°æ®
                            _, buffer = cv2.imencode('.jpg', frame)
                            image_data = buffer.tobytes()
                            
                            # ä¿å­˜å›¾åƒåˆ°æœ¬åœ°å­˜å‚¨
                            filename = storage_manager.generate_filename("captured_photo", ".jpg")
                            saved_path = storage_manager.save_image_from_bytes(
                                image_data, filename, "image_analysis"
                            )
                            
                            if saved_path:
                                print(f"ğŸ“ å›¾åƒå·²ä¿å­˜åˆ°: {saved_path}")
                            else:
                                print("âš ï¸ å›¾åƒä¿å­˜å¤±è´¥ï¼Œä½†ç»§ç»­è¿›è¡Œåˆ†æ")
                            
                            return {
                                'image_data': image_data,
                                'saved_path': saved_path,
                                'frame': frame.copy()  # ä¿ç•™åŸå§‹å¸§ä¾›åç»­ä½¿ç”¨
                            }
                        else:
                            print(f"âŒ æ‘„åƒå¤´ {camera_id} æ— æ³•è¯»å–æœ‰æ•ˆæ•°æ®")
                            
                except Exception as e:
                    print(f"âŒ æ‘„åƒå¤´ {camera_id} æ‹ç…§å¤±è´¥: {e}")
                finally:
                    if cap is not None:
                        cap.release()
                        cap = None
            
            logger.error("æ‰€æœ‰æ‘„åƒå¤´éƒ½æ— æ³•ç”¨äºæ‹ç…§")
            return None
            
        except Exception as e:
            logger.error(f"æ‹ç…§è¿‡ç¨‹å¼‚å¸¸: {e}")
            return None
        finally:
            # ç¡®ä¿èµ„æºé‡Šæ”¾
            if cap is not None:
                cap.release()
            gc.collect()
            cv2.destroyAllWindows()
            print("ğŸ“¸ æ‹ç…§å®Œæˆï¼Œæ‘„åƒå¤´èµ„æºå·²é‡Šæ”¾")
    
    def _encode_image_to_base64(self, image_data: bytes) -> Optional[str]:
        """å°†å›¾åƒæ•°æ®ç¼–ç ä¸ºbase64"""
        try:
            return base64.b64encode(image_data).decode('utf-8')
        except Exception as e:
            logger.error(f"å›¾åƒç¼–ç å¤±è´¥: {e}")
            return None
    
    def _encode_file_to_base64(self, image_path: str) -> Optional[str]:
        """å°†å›¾åƒæ–‡ä»¶ç¼–ç ä¸ºbase64"""
        try:
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
        except Exception as e:
            logger.error(f"æ–‡ä»¶ç¼–ç å¤±è´¥: {e}")
            return None
    
    def _analyze_image(self, base64_image: str, prompt: str) -> Dict[str, Any]:
        """ä½¿ç”¨Azure OpenAIåˆ†æå›¾åƒ"""
        azure_client = self._get_azure_client()
        if not azure_client:
            return {
                'success': False,
                'message': 'Azure OpenAIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–',
                'analysis': None
            }
        
        try:
            response = azure_client.chat.completions.create(
                model="gpt-4.1",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=1000,
                temperature=0.7
            )
            
            analysis_result = response.choices[0].message.content
            
            result = {
                'success': True,
                'message': 'å›¾åƒåˆ†æå®Œæˆ',
                'analysis': analysis_result,
                'timestamp': datetime.now().isoformat(),
                'prompt_used': prompt
            }
            
            return result
            
        except Exception as e:
            logger.error(f"å›¾åƒåˆ†æå¤±è´¥: {e}")
            return {
                'success': False,
                'message': f'åˆ†æå¤±è´¥: {str(e)}',
                'analysis': None
            }
    
    def _capture_and_analyze(self, prompt: str) -> Dict[str, Any]:
        """æ‹ç…§å¹¶åˆ†æï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
        print("ğŸ” å¼€å§‹å›¾åƒåˆ†æï¼šæ‹ç…§ -> ä¿å­˜ -> ç¼–ç  -> AIåˆ†æ")
        
        # æ‹ç…§ï¼ˆå†…éƒ¨å·²åŒ…å«èµ„æºç®¡ç†å’Œæœ¬åœ°ä¿å­˜ï¼‰
        capture_result = self._capture_photo()
        if not capture_result:
            return {
                'success': False,
                'message': 'æ‹ç…§å¤±è´¥ï¼Œæ— æ³•è®¿é—®æ‘„åƒå¤´',
                'data': None
            }
        
        # ç¼–ç å›¾åƒ
        base64_image = self._encode_image_to_base64(capture_result['image_data'])
        if not base64_image:
            return {
                'success': False,
                'message': 'å›¾åƒç¼–ç å¤±è´¥',
                'data': None
            }
        
        print("ğŸ¤– æ­£åœ¨è¿›è¡ŒAIå›¾åƒåˆ†æ...")
        
        # åˆ†æå›¾åƒ
        result = self._analyze_image(base64_image, prompt)
        
        # æ·»åŠ ä¿å­˜çš„å›¾åƒè·¯å¾„ä¿¡æ¯
        if result['success']:
            result['saved_image_path'] = capture_result['saved_path']
            result['image_stored_locally'] = capture_result['saved_path'] is not None
            self._analysis_results.append(result)
            print("âœ… å›¾åƒåˆ†æå®Œæˆ")
        else:
            print("âŒ å›¾åƒåˆ†æå¤±è´¥")
        
        return {
            'success': result['success'],
            'message': 'æ‹ç…§åˆ†æå®Œæˆ' if result['success'] else result['message'],
            'data': result,
            'saved_image_path': capture_result['saved_path']
        }
    
    def _analyze_file(self, image_path: str, prompt: str) -> Dict[str, Any]:
        """åˆ†ææŒ‡å®šå›¾åƒæ–‡ä»¶"""
        if not os.path.exists(image_path):
            return {
                'success': False,
                'message': f'å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}',
                'data': None
            }
        
        # ç¼–ç å›¾åƒæ–‡ä»¶
        base64_image = self._encode_file_to_base64(image_path)
        if not base64_image:
            return {
                'success': False,
                'message': 'å›¾åƒæ–‡ä»¶ç¼–ç å¤±è´¥',
                'data': None
            }
        
        # åˆ†æå›¾åƒ
        result = self._analyze_image(base64_image, prompt)
        result['image_path'] = image_path
        
        if result['success']:
            self._analysis_results.append(result)
        
        return {
            'success': result['success'],
            'message': 'æ–‡ä»¶åˆ†æå®Œæˆ' if result['success'] else result['message'],
            'data': result
        }
    
    def _get_analysis_summary(self) -> Dict[str, Any]:
        """è·å–åˆ†ææ±‡æ€»"""
        successful = len([r for r in self._analysis_results if r.get('success', False)])
        failed = len(self._analysis_results) - successful
        
        # è·å–æœ€æ–°åˆ†æç»“æœ
        latest_analysis = None
        if self._analysis_results:
            latest_analysis = self._analysis_results[-1]
        
        return {
            'total_analyses': len(self._analysis_results),
            'successful': successful,
            'failed': failed,
            'latest_analysis': latest_analysis,
            'camera_available': self._get_camera_manager() is not None,
            'azure_client_available': self._get_azure_client() is not None
        }
    
    def _run(
        self,
        action: str,
        image_path: Optional[str] = None,
        analysis_prompt: str = "è¯·åˆ†æè¿™å¼ å›¾ç‰‡ä¸­çš„äººç‰©æƒ…æ„ŸçŠ¶æ€ï¼Œå¹¶æ ¹æ®æƒ…æ„Ÿæ¨èåˆé€‚çš„éŸ³ä¹é£æ ¼ã€‚åŒ…æ‹¬ï¼š1.äººç‰©è¡¨æƒ…å’Œè‚¢ä½“è¯­è¨€åˆ†æ 2.æƒ…æ„ŸçŠ¶æ€åˆ¤æ–­ 3.éŸ³ä¹é£æ ¼æ¨è",
        run_manager: Optional[CallbackManagerForToolRun] = None,
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥å…·æ“ä½œ"""
        try:
            logger.info(f"æ‰§è¡Œå›¾åƒåˆ†ææ“ä½œ: {action}")
            
            if action == "capture_and_analyze":
                result = self._capture_and_analyze(analysis_prompt)
                
            elif action == "analyze_file":
                if not image_path:
                    return {
                        'success': False,
                        'message': 'ç¼ºå°‘image_pathå‚æ•°',
                        'data': None
                    }
                
                result = self._analyze_file(image_path, analysis_prompt)
                
            elif action == "get_summary":
                summary = self._get_analysis_summary()
                result = {
                    'success': True,
                    'message': 'è·å–åˆ†ææ±‡æ€»æˆåŠŸ',
                    'data': summary
                }
                
            else:
                result = {
                    'success': False,
                    'message': f'ä¸æ”¯æŒçš„æ“ä½œç±»å‹: {action}',
                    'data': None
                }
            
            # ç¡®ä¿ç»“æœå¯ä»¥JSONåºåˆ—åŒ–
            safe_result = ensure_json_serializable(result)
            return safe_result
                
        except Exception as e:
            logger.error(f"å·¥å…·æ‰§è¡Œå¼‚å¸¸: {e}")
            return {
                'success': False,
                'message': f'å·¥å…·æ‰§è¡Œå¼‚å¸¸: {str(e)}',
                'data': None
            }

def main():
    """ç‹¬ç«‹è¿è¡Œæµ‹è¯•å‡½æ•°"""
    print("ï¿½ï¿½ LETDANCE å›¾åƒåˆ†æå·¥å…· - ç‹¬ç«‹æµ‹è¯•")
    print("=" * 50)
    
    # åˆ›å»ºå·¥å…·å®ä¾‹
    tool = ImageAnalysisTool()
    
    # æ˜¾ç¤ºå·¥å…·ä¿¡æ¯
    print(f"å·¥å…·åç§°: {tool.name}")
    print(f"å·¥å…·æè¿°: {tool.description}")
    print(f"Azure OpenAIå¯ç”¨æ€§: {AZURE_AVAILABLE}")
    
    # æµ‹è¯•è·å–æ±‡æ€»
    print("\nğŸ“Š è·å–åˆ†ææ±‡æ€»...")
    summary_result = tool._run(action="get_summary")
    print(f"æ±‡æ€»ç»“æœ: {summary_result}")
    
    # å¦‚æœAzure OpenAIå¯ç”¨ï¼Œæä¾›åˆ†æé€‰é¡¹
    if AZURE_AVAILABLE:
        print("\nğŸ¯ é€‰æ‹©åˆ†ææ¨¡å¼:")
        print("1. æ‹ç…§å¹¶åˆ†æ (éœ€è¦æ‘„åƒå¤´)")
        print("2. åˆ†ææœ¬åœ°å›¾åƒæ–‡ä»¶")
        print("3. è·³è¿‡åˆ†ææµ‹è¯•")
        
        choice = input("è¯·é€‰æ‹© (1/2/3): ").strip()
        
        if choice == '1':
            print("å¼€å§‹æ‹ç…§å¹¶åˆ†æ...")
            analysis_result = tool._run(action="capture_and_analyze")
            print(f"åˆ†æç»“æœ: {analysis_result}")
            
        elif choice == '2':
            image_path = input("è¯·è¾“å…¥å›¾åƒæ–‡ä»¶è·¯å¾„: ").strip()
            if image_path and os.path.exists(image_path):
                print(f"åˆ†æå›¾åƒæ–‡ä»¶: {image_path}")
                analysis_result = tool._run(
                    action="analyze_file",
                    image_path=image_path
                )
                print(f"åˆ†æç»“æœ: {analysis_result}")
            else:
                print("æ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„ä¸ºç©º")
                
        else:
            print("è·³è¿‡åˆ†ææµ‹è¯•")
    else:
        print("\nâš ï¸  Azure OpenAIæœªå®‰è£…ï¼Œæ— æ³•è¿›è¡Œå›¾åƒåˆ†æ")
        print("å®‰è£…å‘½ä»¤: pip install openai")
    
    print("\nâœ… æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    main()